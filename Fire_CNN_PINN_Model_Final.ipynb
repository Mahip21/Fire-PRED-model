{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6beaa754",
   "metadata": {},
   "source": [
    "# üî• Fire Spread Prediction with CNN + PINN\n",
    "This notebook builds a hybrid CNN and PINN model to predict fire spread rate from images, terrain, and geographic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89eb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß SETUP AND LIBRARIES\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from osgeo import gdal\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba69005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ PATHS TO YOUR EXTERNAL DATASETS\n",
    "TRAIN_IMAGE_FOLDER = r'C:\\Users\\Mahip\\Downloads\\Fire_models_Train\\5_Fire_models_Train'  # GR, GS, SH, TL, NB subfolders\n",
    "TEST_IMAGE_FOLDER = r'C:\\Users\\Mahip\\Downloads\\Fire_models_test\\5_Fire_models_test'\n",
    "DEM_FILE_PATH = r'C:\\Users\\Mahip\\Downloads\\TIFF_input\\TIFF_input'\n",
    "PORTUGUESE_ODS_PATH = r'C:\\Users\\Mahip\\Downloads\\PT-FireSprd_L2_FireBehavior_FULL_set.ods'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e97b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üñºÔ∏è DATASET AND AUGMENTATION\n",
    "class FireDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.labels[idx]\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.1)),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.GaussianBlur(3),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3702b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç LOAD IMAGES AND LABELS\n",
    "def load_image_paths(root_folder):\n",
    "    image_paths, labels = [], []\n",
    "    label_map = {'GR': 0, 'GS': 1, 'SH': 2, 'TL': 3, 'NB': 4}\n",
    "    supported_formats = ('.jpg', '.jpeg', '.png')  # ‚úÖ Only use supported image types\n",
    "    for cls in os.listdir(root_folder):\n",
    "        cls_folder = os.path.join(root_folder, cls)\n",
    "        for fname in os.listdir(cls_folder):\n",
    "            if fname.lower().endswith(supported_formats):\n",
    "                image_paths.append(os.path.join(cls_folder, fname))\n",
    "                labels.append(label_map[cls])\n",
    "    return image_paths, labels\n",
    "\n",
    "train_paths, train_labels = load_image_paths(TRAIN_IMAGE_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2144103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahip\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mahip\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# üß† CNN MODEL DEFINITION\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base_model = models.resnet18(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        self.fc = nn.Linear(512, 5)  # üîÅ 5 classes: GR, GS, SH, TL, NB\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "cnn_model = CNNClassifier().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] Accuracy: 89.09%\n",
      "[Fold 2] Accuracy: 89.09%\n",
      "[Fold 3] Accuracy: 90.91%\n",
      "[Fold 4] Accuracy: 94.44%\n"
     ]
    }
   ],
   "source": [
    "# üîÅ CNN TRAINING WITH K-FOLD\n",
    "def train_cnn_kfold(k=5, epochs=10):\n",
    "    kfold = KFold(n_splits=k, shuffle=True)\n",
    "    losses = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(train_paths)):\n",
    "        train_data = FireDataset([train_paths[i] for i in train_idx], [train_labels[i] for i in train_idx], data_transform)\n",
    "        val_data = FireDataset([train_paths[i] for i in val_idx], [train_labels[i] for i in val_idx], data_transform)\n",
    "\n",
    "        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "        model = CNNClassifier().to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                outputs = model(images.to(device))\n",
    "                predicted = torch.argmax(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels.to(device)).sum().item()\n",
    "        acc = 100 * correct / total\n",
    "        losses.append(acc)\n",
    "        print(f\"[Fold {fold + 1}] Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"CNN Accuracy per Fold\")\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.show()\n",
    "    \n",
    "train_cnn_kfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf12960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåÑ DEM FEATURE EXTRACTION FROM MULTIPLE FILES\n",
    "from osgeo import osr\n",
    "\n",
    "def lonlat_to_pixel(geo_transform, lon, lat, srs):\n",
    "    target = osr.SpatialReference()\n",
    "    target.ImportFromEPSG(4326)  # WGS84\n",
    "    transform = osr.CoordinateTransformation(target, srs)\n",
    "    x_geo, y_geo, _ = transform.TransformPoint(lon, lat)\n",
    "    px = int((x_geo - geo_transform[0]) / geo_transform[1])\n",
    "    py = int((y_geo - geo_transform[3]) / geo_transform[5])\n",
    "    return px, py\n",
    "\n",
    "def extract_from_dem_file(dem_path, lon, lat):\n",
    "    ds = gdal.Open(dem_path)\n",
    "    gt = ds.GetGeoTransform()\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromWkt(ds.GetProjection())\n",
    "    band = ds.GetRasterBand(1)\n",
    "    arr = band.ReadAsArray()\n",
    "    x, y = lonlat_to_pixel(gt, lon, lat, srs)\n",
    "\n",
    "    if 0 <= y < arr.shape[0] and 0 <= x < arr.shape[1]:\n",
    "        elevation = arr[y, x]\n",
    "        grad_x, grad_y = np.gradient(arr)\n",
    "        slope = np.hypot(grad_x[y, x], grad_y[y, x])\n",
    "        return elevation, slope\n",
    "    return None, None\n",
    "\n",
    "def extract_dem_features(lon, lat, dem_folder):\n",
    "    for root, _, files in os.walk(dem_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".tif\"):\n",
    "                dem_path = os.path.join(root, file)\n",
    "                elevation, slope = extract_from_dem_file(dem_path, lon, lat)\n",
    "                if elevation is not None:\n",
    "                    return elevation, slope\n",
    "    print(f\"Coordinates ({lon}, {lat}) not found in any DEM file.\")\n",
    "    return 0, 0  # default fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¨ PINN MODEL DEFINITION\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(517, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "pinn_model = PINN().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc2e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† CNN INFERENCE ON IMAGE\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "\n",
    "# This should match training transform except augmentations\n",
    "cnn_infer_transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "def extract_features_from_image(image_path, model, transform=cnn_infer_transform):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.cpu().numpy().flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üóÇÔ∏è PATH TO CNN IMAGE FOLDER USED FOR INFERENCE\n",
    "CNN_IMAGE_FOLDER = r'C:\\Users\\Mahip\\Downloads\\Fire_models_test\\5_Fire_models_test\\TL\\image_63_2.jpeg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f355f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ LOAD PORTUGUESE DATA WITH CLEANED COLUMN NAMES\n",
    "portugal_df = pd.read_excel(PORTUGUESE_ODS_PATH, engine='odf')\n",
    "\n",
    "# Normalize column names (strip + lowercase)\n",
    "portugal_df.columns = [col.strip().lower() for col in portugal_df.columns]\n",
    "\n",
    "# üîÑ Replace these with actual cleaned column names if different\n",
    "def preprocess_portugal_data():\n",
    "    features, targets = [], []\n",
    "    for _, row in portugal_df.iterrows():\n",
    "        lon, lat = row['Longitude'], row['Latitude']\n",
    "        t = row['inidoy,N,11,6']\n",
    "        ros = row['ros_p,N,12,6']\n",
    "        elev, slope = extract_dem_features(lon, lat, DEM_FOLDER_PATH)\n",
    "\n",
    "        # === CNN inference on a dummy image (replace with actual logic) ===\n",
    "        # This assumes a function `extract_features_from_image(image_path)` exists\n",
    "                image_path = CNN_IMAGE_FOLDER\n",
    "        cnn_features = extract_features_from_image(image_path, cnn_model)\n",
    "\n",
    "        full_input = np.concatenate([cnn_features, [lon, lat, t, slope, elev]])\n",
    "        features.append(full_input)\n",
    "        targets.append(ros)\n",
    "    return torch.tensor(features, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Replace this with your DEM folder path\n",
    "DEM_FOLDER_PATH = r'C:\\Users\\Mahip\\Downloads\\TIFF_input\\TIFF_input'\n",
    "\n",
    "X_train, y_train = preprocess_portugal_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbadc5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßÆ PINN TRAINING\n",
    "# üå°Ô∏è True PDE Residual Loss (advection-diffusion)\n",
    "def pde_residual_loss(model, x, device, v=1.0, D=0.1):\n",
    "    x = x.clone().detach().requires_grad_(True).to(device)\n",
    "    \n",
    "    pred = model(x)\n",
    "\n",
    "    # Assume: x[:, -3] = t (time), x[:, -4] = x-position or longitude\n",
    "    t = x[:, -3].view(-1, 1)\n",
    "    pos = x[:, -4].view(-1, 1)\n",
    "\n",
    "    # Compute ‚àÇu/‚àÇt and ‚àÇu/‚àÇx\n",
    "    grad_u = torch.autograd.grad(pred, x, grad_outputs=torch.ones_like(pred),\n",
    "                                 create_graph=True, retain_graph=True)[0]\n",
    "    du_dt = grad_u[:, -3].view(-1, 1)\n",
    "    du_dx = grad_u[:, -4].view(-1, 1)\n",
    "\n",
    "    # Compute ‚àÇ¬≤u/‚àÇx¬≤\n",
    "    grad2_u = torch.autograd.grad(du_dx, x, grad_outputs=torch.ones_like(du_dx),\n",
    "                                  create_graph=True, retain_graph=True)[0]\n",
    "    d2u_dx2 = grad2_u[:, -4].view(-1, 1)\n",
    "\n",
    "    # PDE residual: ‚àÇu/‚àÇt + v ‚àÇu/‚àÇx - D ‚àÇ¬≤u/‚àÇx¬≤ ‚âà 0\n",
    "    residual = du_dt + v * du_dx - D * d2u_dx2\n",
    "    return torch.mean(residual**2)\n",
    "\n",
    "def train_pinn(epochs=1000):\n",
    "    optimizer = torch.optim.Adam(pinn_model.parameters(), lr=1e-4)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        pinn_model.train()\n",
    "\n",
    "        X_train.requires_grad_()  # ‚úÖ Needed for autograd physics loss\n",
    "        pred = pinn_model(X_train.to(device))\n",
    "\n",
    "        mse_loss = F.mse_loss(pred, y_train.to(device))\n",
    "        pde_loss = pde_residual_loss(pinn_model, X_train, device)\n",
    "\n",
    "        loss = mse_loss + 0.1 * pde_loss  # 0.1 = weight for PDE constraint\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, MSE: {mse_loss.item():.4f}, PDE: {pde_loss.item():.4f}, Total: {loss.item():.4f}\")\n",
    "\n",
    "# To train the PINN, uncomment:\n",
    " train_pinn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä FINAL EVALUATION\n",
    "def final_evaluation():\n",
    "    pinn_model.eval()\n",
    "    predictions = pinn_model(X_train.to(device)).cpu().detach().numpy()\n",
    "    true_vals = y_train.cpu().numpy()\n",
    "\n",
    "    plt.plot(predictions, label=\"Predicted ROS\")\n",
    "    plt.plot(true_vals, label=\"True ROS\")\n",
    "    plt.legend()\n",
    "    plt.title(\"PINN Predicted vs True Fire Spread Rate\")\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(\"Rate of Spread\")\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment after training:\n",
    " final_evaluation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebfd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç MANUAL INFERENCE: INPUT IMAGE, LONGITUDE, LATITUDE\n",
    "# Provide these manually before running this cell:\n",
    "\n",
    "IMAGE_PATH = r'C:\\Users\\Mahip\\Downloads\\fire_model_images_by_model-20250430T025324Z-001\\fire_model_images_by_model\\GR6\\image_39_2.jpeg'  # üîÅ Your test image here\n",
    "INPUT_LAT = 41.2                               # üîÅ Your latitude here\n",
    "INPUT_LON = -8.6                               # üîÅ Your longitude here\n",
    "IGNITION_TIME = 3.5                            # üîÅ Time since ignition (hours)\n",
    "\n",
    "# 1. Extract CNN features from provided image\n",
    "cnn_features = extract_features_from_image(IMAGE_PATH, cnn_model)\n",
    "print(\"CNN Features [Texture, Vegetation Type, Moisture, Terrain]:\", cnn_features)\n",
    "\n",
    "# 2. Extract DEM features for given coordinates\n",
    "elevation, slope = extract_dem_features(INPUT_LON, INPUT_LAT, DEM_FOLDER_PATH)\n",
    "print(f\"Slope (radians): {slope:.4f}\")\n",
    "print(f\"Elevation (m): {elevation:.2f}\")\n",
    "\n",
    "# 3. Predict Spread Rate using PINN\n",
    "input_tensor = torch.tensor([*cnn_features, INPUT_LON, INPUT_LAT, IGNITION_TIME, slope, elevation], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "pinn_model.eval()\n",
    "with torch.no_grad():\n",
    "    spread_rate = pinn_model(input_tensor).item()\n",
    "print(f\"Predicted Spread Rate (m/h): {spread_rate:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
